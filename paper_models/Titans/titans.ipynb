{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb3a137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import GPT2LMHeadModel, AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MODEL_NAME = \"gpt2\"\n",
    "LLM_MODEL_PATH = \"/ai/shenwei/workspace/Models/huggingface/gpt2\"\n",
    "LOCAL_DATA_PATH = \"/ai/LLM_DATA/huggingface/wikitext\"\n",
    "MODEL_MAX_POS = 1024  # ⚠️ GPT-2 硬限制\n",
    "MAX_POS = 1024\n",
    "STRIDE = 256\n",
    "MAX_TOKENS = 100_000  # 控制规模\n",
    "\n",
    "def load_tokens():\n",
    "    if os.path.exists(LLM_MODEL_PATH):\n",
    "        tokenizer = AutoTokenizer.from_pretrained(LLM_MODEL_PATH)\n",
    "    else:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    if os.path.exists(LOCAL_DATA_PATH):\n",
    "        ds = load_dataset(f\"{LOCAL_DATA_PATH}/wikitext-103-v1\", split=\"validation\")\n",
    "    else:\n",
    "        ds = load_dataset(\"wikitext\", \"wikitext-103-v1\", split=\"validation\")\n",
    "    text = \"\\n\\n\".join(ds[\"text\"])\n",
    "    tokens = tokenizer(text, return_tensors=\"pt\")[\"input_ids\"][0]\n",
    "    return tokens[:MAX_TOKENS], tokenizer\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_base(model, tokens, max_pos=MAX_POS, stride=STRIDE):\n",
    "    model.eval()\n",
    "    nlls = []\n",
    "    total = 0\n",
    "\n",
    "    for i in tqdm(range(0, len(tokens) - 1, stride), desc=\"GPT-2\"):\n",
    "        if max_pos > MODEL_MAX_POS:\n",
    "            max_pos = MODEL_MAX_POS\n",
    "            stride = max_pos // 4\n",
    "        begin = max(i + stride - max_pos, 0)\n",
    "        end = min(i + stride, len(tokens))\n",
    "        trg_len = end - i\n",
    "\n",
    "        ids = tokens[begin:end].unsqueeze(0).to(DEVICE)\n",
    "        labels = ids.clone()\n",
    "        labels[:, :-trg_len] = -100\n",
    "\n",
    "        out = model(ids, labels=labels)\n",
    "        loss = out.loss.item()\n",
    "        nlls.append(loss * trg_len)\n",
    "        total += trg_len\n",
    "\n",
    "        if end == len(tokens):\n",
    "            break\n",
    "\n",
    "    ppl = math.exp(sum(nlls) / total)\n",
    "    return ppl\n",
    "\n",
    "def main():\n",
    "    tokens, tokenizer = load_tokens()\n",
    "    tokens = tokens.to(DEVICE)\n",
    "\n",
    "    if os.path.exists(LLM_MODEL_PATH):\n",
    "        model = GPT2LMHeadModel.from_pretrained(LLM_MODEL_PATH).to(DEVICE)\n",
    "    else:\n",
    "        model = GPT2LMHeadModel.from_pretrained(MODEL_NAME).to(DEVICE)\n",
    "\n",
    "    ppl = evaluate_base(model, tokens)\n",
    "    print(f\"GPT-2 baseline PPL: {ppl:.2f}\")\n",
    "\n",
    "\n",
    "# main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3591f4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "MEMORY_SIZE = 256\n",
    "MEMORY_ALPHA = 0.1\n",
    "WRITE_FREQ = 4\n",
    "WRITE_TOKENS = 128\n",
    "\n",
    "class TitansMemory(nn.Module):\n",
    "    def __init__(self, d_model, size):\n",
    "        super().__init__()\n",
    "        self.register_buffer(\"mem\", torch.zeros(size, d_model))\n",
    "        self.register_buffer(\"strength\", torch.zeros(size))\n",
    "        self.decay, self.lr = 0.98, 0.05\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def reset(self):\n",
    "        self.mem.zero_()\n",
    "        self.strength.zero_()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def write(self, h, surprise):\n",
    "        s = torch.nan_to_num(surprise.mean(0), 0.0)\n",
    "        k = min(len(s), self.mem.size(0) // 8)\n",
    "        if k == 0:\n",
    "            return\n",
    "        _, idx = torch.topk(s, k)\n",
    "        content = F.normalize(h.mean(0)[idx].detach(), dim=-1)\n",
    "\n",
    "        self.mem.mul_(self.decay)\n",
    "        self.strength.mul_(self.decay)\n",
    "        self.mem[:k] += self.lr * content\n",
    "        self.strength[:k] += s[idx]\n",
    "\n",
    "    def read(self, h):\n",
    "        q = F.normalize(h, dim=-1)\n",
    "        m = F.normalize(self.mem, dim=-1)\n",
    "        attn = torch.einsum(\"btd,md->btm\", q, m)\n",
    "        attn = attn * self.strength\n",
    "        attn = torch.softmax(attn, dim=-1)\n",
    "        return torch.einsum(\"btm,md->btd\", attn, self.mem)\n",
    "\n",
    "class TitansGPT2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        if os.path.exists(LLM_MODEL_PATH):\n",
    "            self.gpt2 = GPT2LMHeadModel.from_pretrained(LLM_MODEL_PATH)\n",
    "        else:\n",
    "            self.gpt2 = GPT2LMHeadModel.from_pretrained(MODEL_NAME)\n",
    "        d = self.gpt2.config.n_embd\n",
    "        self.memory = TitansMemory(d, MEMORY_SIZE)\n",
    "        self.mem_ln = nn.LayerNorm(d)\n",
    "        self.mem_gate = nn.Linear(d,1)\n",
    "\n",
    "    def forward(self, ids, labels, step):\n",
    "        # embed\n",
    "        embeds = self.gpt2.transformer.wte(ids)\n",
    "\n",
    "        # predict for surprise and memory write\n",
    "        with torch.no_grad():\n",
    "            logits_pred = self.gpt2(inputs_embeds=embeds).logits\n",
    "            pred_ids = logits_pred.argmax(-1)\n",
    "            pred_embeds = self.gpt2.transformer.wte(pred_ids)\n",
    "\n",
    "            surprise = torch.norm(\n",
    "                embeds[:,-WRITE_TOKENS:] - pred_embeds[:,-WRITE_TOKENS:], dim=-1\n",
    "            )\n",
    "\n",
    "            if step % WRITE_FREQ == 0:\n",
    "                self.memory.write(embeds[:,-WRITE_TOKENS:], surprise)\n",
    "\n",
    "            mem = self.memory.read(embeds[:,-WRITE_TOKENS:])\n",
    "\n",
    "        mem = self.mem_ln(mem)\n",
    "        gate = torch.sigmoid(self.mem_gate(embeds[:,-WRITE_TOKENS:]))\n",
    "\n",
    "        mod_embeds = embeds.clone()\n",
    "        mod_embeds[:,-WRITE_TOKENS:] += MEMORY_ALPHA * gate * mem\n",
    "\n",
    "        out = self.gpt2(inputs_embeds=mod_embeds, labels=labels)\n",
    "        return out.loss\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_titans(model, tokens, max_pos=MAX_POS, stride=STRIDE):\n",
    "    model.eval()\n",
    "    model.memory.reset()\n",
    "    nlls, total = [], 0\n",
    "\n",
    "    for step, i in enumerate(range(0, len(tokens), stride)):\n",
    "        begin = max(i + stride - max_pos, 0)\n",
    "        end = min(i + stride, len(tokens))\n",
    "        trg_len = end - i\n",
    "\n",
    "        ids = tokens[begin:end].unsqueeze(0).to(DEVICE)\n",
    "        labels = ids.clone()\n",
    "        labels[:,:-trg_len] = -100\n",
    "\n",
    "        loss = model(ids, labels, step).item()\n",
    "        nlls.append(loss * trg_len)\n",
    "        total += trg_len\n",
    "\n",
    "        if end == len(tokens):\n",
    "            break\n",
    "\n",
    "    ppl = math.exp(sum(nlls)/total)\n",
    "    return ppl\n",
    "\n",
    "def main():\n",
    "    tokens, _ = load_tokens()\n",
    "    tokens = tokens.to(DEVICE)\n",
    "\n",
    "    model = TitansGPT2().to(DEVICE)\n",
    "\n",
    "    ppl = evaluate_titans(model, tokens)\n",
    "    print(f\"Titans PPL: {ppl:.2f}\")\n",
    "\n",
    "\n",
    "# main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fb78e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitansMemory(nn.Module):\n",
    "    def __init__(self, d_model, size):\n",
    "        super().__init__()\n",
    "        self.register_buffer(\"mem\", torch.zeros(size, d_model))\n",
    "        self.register_buffer(\"strength\", torch.zeros(size))\n",
    "        self.decay = 0.98\n",
    "        self.lr = 0.05\n",
    "        self.ptr = 0   # circular buffer\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def reset(self):\n",
    "        self.mem.zero_()\n",
    "        self.strength.zero_()\n",
    "        self.ptr = 0\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def write(self, h, surprise):\n",
    "        \"\"\"\n",
    "        h: [B, T, D]  —— 即将被移出 attention window 的 token\n",
    "        \"\"\"\n",
    "        s = torch.nan_to_num(surprise.mean(0), 0.0)\n",
    "        if s.numel() == 0:\n",
    "            return\n",
    "\n",
    "        k = min(len(s), self.mem.size(0) // 8)\n",
    "        _, idx = torch.topk(s, k)\n",
    "\n",
    "        content = F.normalize(h.mean(0)[idx], dim=-1)\n",
    "\n",
    "        for i in range(k):\n",
    "            self.mem[self.ptr] = content[i]\n",
    "            self.strength[self.ptr] = s[idx[i]]\n",
    "            self.ptr = (self.ptr + 1) % self.mem.size(0)\n",
    "    \n",
    "    def read(self, q):\n",
    "        if self.strength.sum() == 0:\n",
    "            return torch.zeros_like(q)\n",
    "\n",
    "        q = F.normalize(q, dim=-1)\n",
    "        m = F.normalize(self.mem, dim=-1)\n",
    "\n",
    "        attn = torch.einsum(\"btd,md->btm\", q, m)\n",
    "        attn = attn * self.strength\n",
    "        attn = torch.softmax(attn, dim=-1)\n",
    "\n",
    "        return torch.einsum(\"btm,md->btd\", attn, self.mem)\n",
    "\n",
    "class TitansGPT2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        if os.path.exists(LLM_MODEL_PATH):\n",
    "            self.gpt2 = GPT2LMHeadModel.from_pretrained(LLM_MODEL_PATH)\n",
    "        else:\n",
    "            self.gpt2 = GPT2LMHeadModel.from_pretrained(MODEL_NAME)\n",
    "        d = self.gpt2.config.n_embd\n",
    "\n",
    "        self.memory = TitansMemory(d, MEMORY_SIZE)\n",
    "        self.mem_ln = nn.LayerNorm(d)\n",
    "        self.mem_gate = nn.Linear(d, 1)\n",
    "\n",
    "    def forward(self, ids, labels, step):\n",
    "        embeds = self.gpt2.transformer.wte(ids)\n",
    "\n",
    "        # 写 memory：只在 window 滑动时\n",
    "        if step > 0 and step % WRITE_FREQ == 0:\n",
    "            with torch.no_grad():\n",
    "                logits = self.gpt2(inputs_embeds=embeds).logits\n",
    "                pred = logits.argmax(-1)\n",
    "                pred_emb = self.gpt2.transformer.wte(pred)\n",
    "\n",
    "                surprise = torch.norm(\n",
    "                    embeds[:, :WRITE_TOKENS] - pred_emb[:, :WRITE_TOKENS],\n",
    "                    dim=-1\n",
    "                )\n",
    "\n",
    "                self.memory.write(\n",
    "                    embeds[:, :WRITE_TOKENS],\n",
    "                    surprise\n",
    "                )\n",
    "\n",
    "        # 读 memory（补充历史）\n",
    "        mem = self.memory.read(embeds)\n",
    "        mem = self.mem_ln(mem)\n",
    "        gate = torch.sigmoid(self.mem_gate(embeds))\n",
    "\n",
    "        mod_embeds = embeds + MEMORY_ALPHA * gate * mem\n",
    "\n",
    "        out = self.gpt2(inputs_embeds=mod_embeds, labels=labels)\n",
    "        return out.loss\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_titans(model, tokens, max_pos=1024, stride=256):\n",
    "    model.eval()\n",
    "    model.memory.reset()\n",
    "\n",
    "    nlls, total = [], 0\n",
    "\n",
    "    for step, i in enumerate(range(0, len(tokens) - 1, stride)):\n",
    "        begin = max(0, i + stride - max_pos)\n",
    "        end = min(i + stride, len(tokens) - 1)\n",
    "\n",
    "        ids = tokens[begin:end].unsqueeze(0)\n",
    "        labels = tokens[begin+1:end+1].unsqueeze(0)\n",
    "\n",
    "        loss = model(ids, labels, step)\n",
    "        nlls.append(loss.item() * (end - i))\n",
    "        total += (end - i)\n",
    "\n",
    "        if end == len(tokens) - 1:\n",
    "            break\n",
    "\n",
    "    return math.exp(sum(nlls) / total)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0a8187",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 画图 \n",
    "def picture():\n",
    "    windows = [512, 1024, 2048, 4096]\n",
    "    baseline_ppls = []\n",
    "    titans_ppls = []\n",
    "    if os.path.exists(LLM_MODEL_PATH):\n",
    "        gpt2_model = GPT2LMHeadModel.from_pretrained(LLM_MODEL_PATH).to(DEVICE)\n",
    "    else:\n",
    "        gpt2_model = GPT2LMHeadModel.from_pretrained(MODEL_NAME).to(DEVICE)\n",
    "\n",
    "    titans_model = TitansGPT2().to(DEVICE)\n",
    "\n",
    "    for w in windows:\n",
    "        stride = w // 4\n",
    "        max_pos = w\n",
    "\n",
    "        print(f\"Context Window: {w}, Stride: {stride}\")\n",
    "\n",
    "        tokens, _ = load_tokens()\n",
    "        tokens = tokens.to(DEVICE)\n",
    "        gpt2_ppl = evaluate_base(gpt2_model, tokens, max_pos=max_pos, stride=stride)\n",
    "        baseline_ppls.append(gpt2_ppl)\n",
    "\n",
    "        t_ppl = evaluate_titans(titans_model, tokens, max_pos=max_pos, stride=stride)\n",
    "        titans_ppls.append(t_ppl)\n",
    "\n",
    "    plt.plot(windows, baseline_ppls, label=\"GPT-2\")\n",
    "    plt.plot(windows, titans_ppls, label=\"Titans\")\n",
    "    plt.xlabel(\"Context Window\")\n",
    "    plt.ylabel(\"PPL\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    for w in windows:\n",
    "        print(f\"Context Window: {w}\")\n",
    "        print(\"Titans PPL:\", titans_ppls[windows.index(w)])\n",
    "        print(\"GPT-2 PPL:\", baseline_ppls[windows.index(w)])\n",
    "        print()\n",
    "\n",
    "picture()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9740d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ai/shenwei/workspace/codes/ModelServe/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "MODEL_NAME = \"gpt2\"\n",
    "MODEL_MAX_POS = 1024      # ⚠️ GPT-2 硬限制\n",
    "STRIDE = 256              # sliding step\n",
    "\n",
    "LLM_MODEL_PATH = \"/ai/shenwei/workspace/Models/huggingface/gpt2\"\n",
    "LOCAL_DATA_PATH = \"/ai/LLM_DATA/huggingface/wikitext\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4050762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wikitext_tokens():\n",
    "    if os.path.exists(LLM_MODEL_PATH):\n",
    "        tokenizer = GPT2TokenizerFast.from_pretrained(LLM_MODEL_PATH)\n",
    "    else:\n",
    "        tokenizer = GPT2TokenizerFast.from_pretrained(MODEL_NAME)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    if os.path.exists(LOCAL_DATA_PATH):\n",
    "        dataset = load_dataset(f\"{LOCAL_DATA_PATH}/wikitext-2-raw-v1\", split=\"test\")\n",
    "    else:\n",
    "        dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\", split=\"test\")\n",
    "    text = \"\\n\\n\".join(dataset[\"text\"])\n",
    "\n",
    "    tokens = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=False\n",
    "    ).input_ids[0]\n",
    "\n",
    "    return tokens.to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23938b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_gpt2_sliding(model, tokens):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "\n",
    "    for start in tqdm(range(0, len(tokens) - 1, STRIDE), desc=\"GPT-2\"):\n",
    "        end = min(start + MODEL_MAX_POS, len(tokens) - 1)\n",
    "        input_ids = tokens[start:end].unsqueeze(0)\n",
    "        labels = tokens[start + 1:end + 1].unsqueeze(0)\n",
    "\n",
    "        outputs = model(input_ids, labels=labels)\n",
    "        losses.append(outputs.loss.item())\n",
    "\n",
    "    return math.exp(sum(losses) / len(losses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a205a007",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitansMemory:\n",
    "    def __init__(self, hidden_size, max_steps):\n",
    "        self.hidden_size = hidden_size\n",
    "        self.max_steps = max_steps\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.bank = []\n",
    "\n",
    "    def write(self, hidden):\n",
    "        # hidden: [1, T, H] → [H]\n",
    "        summary = hidden.mean(dim=1).squeeze(0).detach()\n",
    "        self.bank.append(summary)\n",
    "        if len(self.bank) > self.max_steps:\n",
    "            self.bank.pop(0)\n",
    "\n",
    "    def read(self):\n",
    "        if len(self.bank) == 0:\n",
    "            return None\n",
    "        return torch.stack(self.bank, dim=0).mean(dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "485e979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitansGPT2(nn.Module):\n",
    "    def __init__(self, memory_steps):\n",
    "        super().__init__()\n",
    "        if os.path.exists(LLM_MODEL_PATH):\n",
    "            self.model = GPT2LMHeadModel.from_pretrained(LLM_MODEL_PATH).to(DEVICE)\n",
    "        else:\n",
    "            self.model = GPT2LMHeadModel.from_pretrained(MODEL_NAME).to(DEVICE)\n",
    "        self.hidden = self.model.config.n_embd\n",
    "        self.memory = TitansMemory(self.hidden, memory_steps)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, input_ids, labels):\n",
    "        out = self.model(\n",
    "            input_ids=input_ids,\n",
    "            output_hidden_states=True,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        last_hidden = out.hidden_states[-1]\n",
    "        self.memory.write(last_hidden)\n",
    "\n",
    "        mem = self.memory.read()\n",
    "        if mem is not None:\n",
    "            out.logits[:, -1, :] += torch.matmul(\n",
    "                self.model.lm_head.weight,\n",
    "                mem\n",
    "            )\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dafd5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_titans(tokens, effective_context):\n",
    "    memory_steps = max(1, (effective_context - MODEL_MAX_POS) // STRIDE)\n",
    "    model = TitansGPT2(memory_steps)\n",
    "    model.eval()\n",
    "    model.memory.reset()\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for start in tqdm(range(0, len(tokens) - 1, STRIDE), desc=f\"Titans@{effective_context}\"):\n",
    "        end = min(start + MODEL_MAX_POS, len(tokens) - 1)\n",
    "\n",
    "        input_ids = tokens[start:end].unsqueeze(0)\n",
    "        labels = tokens[start + 1:end + 1].unsqueeze(0)\n",
    "\n",
    "        out = model(input_ids, labels)\n",
    "        losses.append(out.loss.item())\n",
    "\n",
    "    return math.exp(sum(losses) / len(losses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a9e451f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (287644 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating GPT-2 baseline (effective ≤1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPT-2:   0%|          | 0/1124 [00:00<?, ?it/s]`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n",
      "GPT-2: 100%|██████████| 1124/1124 [00:23<00:00, 48.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Titans (effective context = 2048)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Titans@2048: 100%|██████████| 1124/1124 [00:23<00:00, 48.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "GPT-2   PPL : 8772.58\n",
      "Titans PPL : 8772.58\n",
      "==============================\n",
      "\n",
      "Evaluating Titans (effective context = 4096)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Titans@4096: 100%|██████████| 1124/1124 [00:23<00:00, 48.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "GPT-2   PPL : 8772.58\n",
      "Titans PPL : 8772.58\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokens = load_wikitext_tokens()\n",
    "\n",
    "if os.path.exists(LLM_MODEL_PATH):\n",
    "    gpt2 = GPT2LMHeadModel.from_pretrained(LLM_MODEL_PATH).to(DEVICE)\n",
    "else:\n",
    "    gpt2 = GPT2LMHeadModel.from_pretrained(MODEL_NAME).to(DEVICE)\n",
    "gpt2.eval()\n",
    "\n",
    "print(\"\\nEvaluating GPT-2 baseline (effective ≤1024)\")\n",
    "gpt2_ppl = eval_gpt2_sliding(gpt2, tokens)\n",
    "\n",
    "for ctx in [2048, 4096]:\n",
    "    print(f\"\\nEvaluating Titans (effective context = {ctx})\")\n",
    "    titans_ppl = eval_titans(tokens, ctx)\n",
    "\n",
    "    print(\"==============================\")\n",
    "    print(f\"GPT-2   PPL : {gpt2_ppl:.2f}\")\n",
    "    print(f\"Titans PPL : {titans_ppl:.2f}\")\n",
    "    print(\"==============================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe42fdd0",
   "metadata": {},
   "source": [
    "| 项目               | 设置              |\n",
    "| ---------------- | --------------- |\n",
    "| Base model       | GPT-2           |\n",
    "| Attention window | 1024            |\n",
    "| Stride           | 256             |\n",
    "| Dataset          | WikiText-2 test |\n",
    "| Metric           | PPL             |\n",
    "| Eval             | sliding window  |\n",
    "| Memory           | test-time only  |\n",
    "| Seeds            | 固定              |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99e9e427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import GPT2LMHeadModel, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "LLM_MODEL_PATH = \"/ai/shenwei/workspace/Models/huggingface/gpt2\"\n",
    "LOCAL_DATA_PATH = \"/ai/LLM_DATA/huggingface/wikitext\"\n",
    "MODEL_NAME = \"gpt2\"\n",
    "MAX_POS = 1024\n",
    "STRIDE = 256\n",
    "OVERLAP = MAX_POS - STRIDE\n",
    "\n",
    "# ---- Titans memory hyperparams ----\n",
    "WRITE_TOKENS = 128\n",
    "MEMORY_SIZE = 24        # 24 × 128 = 3072 → effective ≈ 4096\n",
    "MEMORY_ALPHA = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "412cf9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tokens():\n",
    "    if os.path.exists(LLM_MODEL_PATH):\n",
    "        tokenizer = AutoTokenizer.from_pretrained(LLM_MODEL_PATH)\n",
    "    else:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    if os.path.exists(LOCAL_DATA_PATH):\n",
    "        ds = load_dataset(f\"{LOCAL_DATA_PATH}/wikitext-103-v1\", split=\"validation\")\n",
    "    else:\n",
    "        ds = load_dataset(\"wikitext\", \"wikitext-103-v1\", split=\"validation\")\n",
    "    text = \"\\n\\n\".join(ds[\"text\"])\n",
    "    tokens = tokenizer(text, return_tensors=\"pt\")[\"input_ids\"][0]\n",
    "    return tokens.to(DEVICE)  # [:MAX_TOKENS], tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0ebc40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitansMemory(nn.Module):\n",
    "    def __init__(self, d_model, size):\n",
    "        super().__init__()\n",
    "        self.size = size\n",
    "        self.register_buffer(\"mem\", torch.zeros(size, d_model))\n",
    "        self.register_buffer(\"strength\", torch.zeros(size))\n",
    "        self.ptr = 0\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def reset(self):\n",
    "        self.mem.zero_()\n",
    "        self.strength.zero_()\n",
    "        self.ptr = 0\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def old_write(self, h, surprise=None):\n",
    "        \"\"\"\n",
    "        h: [B, T, D]   (T = WRITE_TOKENS)\n",
    "        surprise: [B, T]\n",
    "        \"\"\"\n",
    "        if surprise is None:\n",
    "            content = F.normalize(h.mean(0), dim=-1)\n",
    "\n",
    "            for i in range(min(len(content), self.size)):\n",
    "                self.mem[self.ptr] = content[i]\n",
    "                self.strength[self.ptr] = 1.0\n",
    "                self.ptr = (self.ptr + 1) % self.size\n",
    "        else:\n",
    "            s = torch.nan_to_num(surprise.mean(0), 0.0)\n",
    "            if s.numel() == 0:\n",
    "                return\n",
    "\n",
    "            k = min(len(s), self.size // 4)\n",
    "            _, idx = torch.topk(s, k)\n",
    "\n",
    "            content = F.normalize(h.mean(0)[idx], dim=-1)\n",
    "\n",
    "            for i in range(k):\n",
    "                self.mem[self.ptr] = content[i]\n",
    "                self.strength[self.ptr] = s[idx[i]]\n",
    "                self.ptr = (self.ptr + 1) % self.size\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def write(self, h, surprise=None):\n",
    "        \"\"\"\n",
    "        h: [B, T, D]   tokens guaranteed to be OUTSIDE future windows\n",
    "        \"\"\"\n",
    "        B, T, D = h.shape\n",
    "        if T == 0:\n",
    "            return\n",
    "\n",
    "        max_k = min(self.size // 4, T)\n",
    "        if max_k <= 0:\n",
    "            return\n",
    "\n",
    "        if surprise is not None:\n",
    "            s = torch.nan_to_num(surprise.mean(0), 0.0)\n",
    "            k = min(max_k, s.numel())\n",
    "            _, idx = torch.topk(s, k)\n",
    "            idx = idx.clamp(0, T - 1)\n",
    "        else:\n",
    "            k = max_k\n",
    "            idx = torch.arange(k, device=h.device)\n",
    "\n",
    "        content = F.normalize(h.mean(0)[idx], dim=-1)\n",
    "\n",
    "        for i in range(k):\n",
    "            self.mem[self.ptr].copy_(content[i])\n",
    "            self.strength[self.ptr] = 1.0\n",
    "            self.ptr = (self.ptr + 1) % self.size\n",
    "\n",
    "    def read(self, q):\n",
    "        if self.strength.sum() == 0:\n",
    "            return torch.zeros_like(q)\n",
    "\n",
    "        q = F.normalize(q, dim=-1)\n",
    "        m = F.normalize(self.mem, dim=-1)\n",
    "\n",
    "        attn = torch.einsum(\"btd,md->btm\", q, m)\n",
    "        attn = attn * self.strength\n",
    "        attn = torch.softmax(attn, dim=-1)\n",
    "\n",
    "        return torch.einsum(\"btm,md->btd\", attn, self.mem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "748397d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitansGPT2(nn.Module):\n",
    "    def __init__(self, memory_size=MEMORY_SIZE, use_surprise=True, use_gate=True):\n",
    "        super().__init__()\n",
    "        if os.path.exists(LLM_MODEL_PATH):\n",
    "            self.gpt2 = GPT2LMHeadModel.from_pretrained(LLM_MODEL_PATH).to(DEVICE)\n",
    "        else:\n",
    "            self.gpt2 = GPT2LMHeadModel.from_pretrained(MODEL_NAME).to(DEVICE)\n",
    "        d = self.gpt2.config.n_embd\n",
    "\n",
    "        self.memory = TitansMemory(d, memory_size)\n",
    "        self.mem_ln = nn.LayerNorm(d)\n",
    "        self.mem_gate = nn.Linear(d, 1)\n",
    "\n",
    "        # \n",
    "        self.use_surprise = use_surprise\n",
    "        self.use_gate = use_gate\n",
    "\n",
    "    def old_forward(self, ids, labels, step):\n",
    "        embeds = self.gpt2.transformer.wte(ids)\n",
    "\n",
    "        # ---- write memory: tokens that are sliding out ----\n",
    "        if step > 0:\n",
    "            with torch.no_grad():\n",
    "                h_old = embeds[:, :WRITE_TOKENS]\n",
    "\n",
    "                logits = self.gpt2(inputs_embeds=embeds).logits\n",
    "                pred = logits.argmax(-1)\n",
    "                pred_emb = self.gpt2.transformer.wte(pred)\n",
    "                \n",
    "                if self.use_surprise:\n",
    "                    surprise = torch.norm(\n",
    "                        h_old - pred_emb[:, :WRITE_TOKENS],\n",
    "                        dim=-1\n",
    "                    )\n",
    "\n",
    "                    self.memory.write(h_old, surprise)\n",
    "                else:\n",
    "                    self.memory.write(h_old)\n",
    "\n",
    "        # ---- read memory ----\n",
    "        mem = self.memory.read(embeds)\n",
    "        mem = self.mem_ln(mem)\n",
    "        gate = torch.sigmoid(self.mem_gate(embeds))\n",
    "\n",
    "        if self.use_gate:\n",
    "            mod_embeds = embeds + MEMORY_ALPHA * gate * mem\n",
    "        else:\n",
    "            mod_embeds = embeds + MEMORY_ALPHA * mem\n",
    "\n",
    "        out = self.gpt2(inputs_embeds=mod_embeds, labels=labels)\n",
    "        return out.loss\n",
    "    \n",
    "    def forward(self, ids, labels, prev_embeds=None):\n",
    "        embeds = self.gpt2.transformer.wte(ids)\n",
    "\n",
    "        # ---- write ONLY non-overlapping tokens ----\n",
    "        if prev_embeds is not None:\n",
    "            with torch.no_grad():\n",
    "                write_region = prev_embeds[:, :OVERLAP]\n",
    "\n",
    "                if self.use_surprise:\n",
    "                    logits = self.gpt2(inputs_embeds=write_region).logits\n",
    "                    pred = logits.argmax(-1)\n",
    "                    pred_emb = self.gpt2.transformer.wte(pred)\n",
    "                    surprise = torch.norm(write_region - pred_emb, dim=-1)\n",
    "                else:\n",
    "                    surprise = None\n",
    "\n",
    "                tail = write_region[:, -WRITE_TOKENS:]\n",
    "                self.memory.write(tail, surprise)\n",
    "\n",
    "        # ---- read memory ----\n",
    "        mem = self.mem_ln(self.memory.read(embeds))\n",
    "\n",
    "        if self.use_gate:\n",
    "            gate = torch.sigmoid(self.mem_gate(embeds))\n",
    "            embeds = embeds + MEMORY_ALPHA * gate * mem\n",
    "        else:\n",
    "            embeds = embeds + MEMORY_ALPHA * mem\n",
    "\n",
    "        out = self.gpt2(inputs_embeds=embeds, labels=labels)\n",
    "        return out.loss, embeds.detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e0bdc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_titans(model, tokens):\n",
    "    model.eval()\n",
    "    model.memory.reset()\n",
    "\n",
    "    nlls, total = [], 0\n",
    "    prev_embeds = None\n",
    "\n",
    "    for i in tqdm(range(0, len(tokens) - 1, STRIDE)):\n",
    "        begin = max(0, i + STRIDE - MAX_POS)\n",
    "        end = min(i + STRIDE, len(tokens) - 1)\n",
    "\n",
    "        ids = tokens[begin:end].unsqueeze(0).to(DEVICE)\n",
    "        labels = tokens[begin+1:end+1].unsqueeze(0).to(DEVICE)\n",
    "\n",
    "        loss, curr_embeds = model(ids, labels, prev_embeds)\n",
    "\n",
    "        nlls.append(loss.item() * (end - i))\n",
    "        total += (end - i)\n",
    "\n",
    "        prev_embeds = curr_embeds\n",
    "\n",
    "        if end == len(tokens) - 1:\n",
    "            break\n",
    "\n",
    "    return math.exp(sum(nlls) / total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8edf97c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_gpt2(tokens):\n",
    "    if os.path.exists(LLM_MODEL_PATH):\n",
    "        model = GPT2LMHeadModel.from_pretrained(LLM_MODEL_PATH).to(DEVICE)\n",
    "    else:\n",
    "        model = GPT2LMHeadModel.from_pretrained(MODEL_NAME).to(DEVICE)\n",
    "    model.eval()\n",
    "\n",
    "    nlls, total = [], 0\n",
    "\n",
    "    for i in tqdm(range(0, len(tokens) - 1, STRIDE), desc=\"GPT-2\"):\n",
    "        begin = max(0, i + STRIDE - MAX_POS)\n",
    "        end = min(i + STRIDE, len(tokens) - 1)\n",
    "\n",
    "        ids = tokens[begin:end].unsqueeze(0)\n",
    "        labels = tokens[begin+1:end+1].unsqueeze(0)\n",
    "\n",
    "        loss = model(ids, labels=labels).loss\n",
    "        nlls.append(loss.item() * (end - i))\n",
    "        total += (end - i)\n",
    "\n",
    "        if end == len(tokens) - 1:\n",
    "            break\n",
    "\n",
    "    return math.exp(sum(nlls) / total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1dd5377f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (250896 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating GPT-2 baseline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPT-2: 100%|█████████▉| 980/981 [00:20<00:00, 48.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Titans (effective context > 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Titans: 100%|█████████▉| 980/981 [00:41<00:00, 23.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "GPT-2   PPL : 7876.41\n",
      "Titans PPL : 5367.92\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    tokens = load_tokens()\n",
    "\n",
    "    print(\"\\nEvaluating GPT-2 baseline\")\n",
    "    gpt2_ppl = evaluate_gpt2(tokens)\n",
    "\n",
    "    print(\"\\nEvaluating Titans (effective context > 1024)\")\n",
    "    titans = TitansGPT2().to(DEVICE)\n",
    "    titans_ppl = evaluate_titans(titans, tokens)\n",
    "\n",
    "    print(\"\\n==============================\")\n",
    "    print(f\"GPT-2   PPL : {gpt2_ppl:.2f}\")\n",
    "    print(f\"Titans PPL : {titans_ppl:.2f}\")\n",
    "    print(\"==============================\")\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "307e216e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sweep_memory_size(tokens):\n",
    "    results = {}\n",
    "\n",
    "    for m in [4, 8, 16, 24]:\n",
    "        print(f\"\\nEvaluating Titans MEMORY_SIZE={m}\")\n",
    "        model = TitansGPT2(memory_size=m).to(DEVICE)\n",
    "\n",
    "        ppl = evaluate_titans(model, tokens)\n",
    "        results[m] = ppl\n",
    "\n",
    "        print(f\"MEMORY_SIZE={m} → PPL={ppl:.2f}\")\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e38660",
   "metadata": {},
   "source": [
    "**绘图**  \n",
    "**结论**：Increasing memory capacity consistently reduces perplexity, confirming that Titans effectively exploits test-time memory to extend context beyond the transformer window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "032f79d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_memory_sweep(results):\n",
    "    xs = [k * WRITE_TOKENS + 1024 for k in results.keys()]\n",
    "    ys = list(results.values())\n",
    "\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(xs, ys, marker=\"o\")\n",
    "    plt.xlabel(\"Effective Context Length\")\n",
    "    plt.ylabel(\"Perplexity (↓)\")\n",
    "    plt.title(\"Titans: Memory Size vs Perplexity\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"memory_sweep_ppl.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a763dd63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (250896 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Titans MEMORY_SIZE=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Titans:   0%|          | 0/981 [00:00<?, ?it/s]`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n",
      "Titans: 100%|█████████▉| 980/981 [00:40<00:00, 24.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEMORY_SIZE=4 → PPL=5474.50\n",
      "\n",
      "Evaluating Titans MEMORY_SIZE=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Titans: 100%|█████████▉| 980/981 [00:40<00:00, 24.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEMORY_SIZE=8 → PPL=5284.78\n",
      "\n",
      "Evaluating Titans MEMORY_SIZE=16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Titans: 100%|█████████▉| 980/981 [00:40<00:00, 24.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEMORY_SIZE=16 → PPL=5039.59\n",
      "\n",
      "Evaluating Titans MEMORY_SIZE=24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Titans: 100%|█████████▉| 980/981 [00:40<00:00, 24.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEMORY_SIZE=24 → PPL=4954.69\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokens = load_tokens()\n",
    "results = sweep_memory_size(tokens)\n",
    "plot_memory_sweep(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdacec5f",
   "metadata": {},
   "source": [
    "* Step 2 Ablation：no surprise / no gate\n",
    "* 2.1 Ablation 1：no surprise\n",
    "    * 所有 token 都写，等价于 naive cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af577ce7",
   "metadata": {},
   "source": [
    "* 2.2 Ablation 2：no gate\n",
    "* 结论：Removing surprise-based writing or gating significantly degrades performance, highlighting their necessity for effective memory utilization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "882ddf2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 980/981 [00:36<00:00, 26.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Titans: PPL=5289.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 980/981 [00:21<00:00, 45.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Surprise: PPL=5194.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 980/981 [00:36<00:00, 26.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Gate: PPL=2331.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def run_ablations(tokens):\n",
    "    configs = {\n",
    "        \"Full Titans\": dict(surprise=True, gate=True),\n",
    "        \"No Surprise\": dict(surprise=False, gate=True),\n",
    "        \"No Gate\": dict(surprise=True, gate=False),\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "    for name, cfg in configs.items():\n",
    "        model = TitansGPT2(memory_size=16).to(DEVICE)\n",
    "        model.use_surprise = cfg[\"surprise\"]\n",
    "        model.use_gate = cfg[\"gate\"]\n",
    "\n",
    "        ppl = evaluate_titans(model, tokens)\n",
    "        results[name] = ppl\n",
    "\n",
    "        print(f\"{name}: PPL={ppl:.2f}\")\n",
    "\n",
    "    return results\n",
    "# tokens = None\n",
    "if tokens is None:\n",
    "    tokens = load_tokens()\n",
    "results = run_ablations(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1d2c4b",
   "metadata": {},
   "source": [
    "* Step 3 迁移到 Mistral-7B (8k)\n",
    "* 3.1 关键变化点  \n",
    "\n",
    "\n",
    "| 项目            | GPT-2    | Mistral |\n",
    "| ------------- | -------- | ------- |\n",
    "| Pos Embedding | absolute | RoPE    |\n",
    "| Max length    | 1024     | 8192    |\n",
    "| Memory gain   | ×2–4     | ×2–4    |\n",
    "\n",
    "* 3.2 替换模型\n",
    "\n",
    "```python\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "MODEL_NAME = \"mistralai/Mistral-7B-v0.1\"\n",
    "\n",
    "self.model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "```\n",
    "⚠️ Memory injection 放在 attention 前的 hidden_states，不碰 RoPE\n",
    "\n",
    "* 3.3 Mistral 的意义  \n",
    "GPT-2 verifies concept feasibility, while Mistral demonstrates scalability to modern long-context LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c07c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Mistral Titans 核心差异:\n",
    "不碰 position embedding\n",
    "只改 hidden_states\n",
    "attention window = 8192\n",
    "memory 逻辑完全一致\n",
    "\"\"\"\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "MODEL_NAME = \"mistralai/Mistral-7B-v0.1\"\n",
    "\n",
    "class TitansMistral(nn.Module):\n",
    "    def __init__(self, memory_size):\n",
    "        super().__init__()\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            MODEL_NAME,\n",
    "            torch_dtype=torch.float16,\n",
    "            device_map=\"auto\"\n",
    "        )\n",
    "\n",
    "        d = self.model.config.hidden_size\n",
    "        self.memory = TitansMemory(d, memory_size)\n",
    "        self.mem_ln = nn.LayerNorm(d)\n",
    "        self.mem_gate = nn.Linear(d, 1)\n",
    "\n",
    "    def forward(self, input_ids, labels, prev_hidden=None):\n",
    "        out = self.model(\n",
    "            input_ids=input_ids,\n",
    "            output_hidden_states=True,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        hidden = out.hidden_states[-1]\n",
    "\n",
    "        if prev_hidden is not None:\n",
    "            self.memory.write(prev_hidden[:, -WRITE_TOKENS:])\n",
    "\n",
    "        mem = self.mem_ln(self.memory.read(hidden))\n",
    "        gate = torch.sigmoid(self.mem_gate(hidden))\n",
    "\n",
    "        hidden = hidden + MEMORY_ALPHA * gate * mem\n",
    "\n",
    "        logits = self.model.lm_head(hidden)\n",
    "        loss = F.cross_entropy(\n",
    "            logits.view(-1, logits.size(-1)),\n",
    "            labels.view(-1),\n",
    "            ignore_index=-100\n",
    "        )\n",
    "\n",
    "        return loss, hidden.detach()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ModelServe (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
