# [DeepSeek-V3.2](https://arxiv.org/abs/2512.02556)：开源大模型的“效率+能力”双突破
这篇技术报告的核心目标是**缩小开源大模型与闭源模型（如GPT-5、Gemini-3.0-Pro）的差距**——既要让开源模型具备顶尖的推理、工具使用能力，又要保证计算效率高、部署成本低。报告针对性解决了开源模型的三大痛点，并用三大核心技术实现突破，最终推出了“标准版DeepSeek-V3.2”和“强化推理版DeepSeek-V3.2-Speciale”，后者甚至拿下了国际数学/信息学奥赛金牌。


## 一、要解决什么问题？
之前开源大模型和闭源模型的差距越来越大，核心是三个“短板”：
1. **长文本处理效率低**：传统模型处理长文本（比如128K字的文档）时，每个词都要和所有词“打招呼”，计算量呈平方增长，又慢又费资源；
2. **后续训练资源不足**：开源模型往往“预训练阶段用力，后续优化偷懒”，后续训练的算力不到预训练的10%，导致复杂任务（如数学证明、代码调试）表现差；
3. **工具使用能力弱**：面对搜索、编程、代码解释器等工具，开源模型不会“举一反三”，在真实场景中容易掉链子。

而DeepSeek-V3.2的目标，就是用三大技术补齐这三个短板，让开源模型也能“又快又能打”。


## 二、三大核心技术
### 技术1：DeepSeek Sparse Attention（DSA）—— 长文本处理的“效率神器”
#### 问题背景
传统大模型的“注意力机制”是“地毯式搜索”：比如处理128K字的文档，每个字都要和其他128K字逐一计算相关性，计算量是“128K×128K”（约1.6亿次），相当于让一个人读完一本书后，回忆每个句子和所有句子的关系，又慢又累。

#### 核心思路：“挑重点”替代“全覆盖”
DSA的本质是“只关注重要的词”，把计算量从“平方级”（O(L²)）降到“线性级”（O(L×k)，k是每个词关注的重点词数，比如2048），相当于让读者只记住和当前句子相关的关键内容，效率翻倍。

#### DSA的两个关键部分
1. **闪电索引器（Lightning Indexer）**：快速“打分”筛选重点  
   就像一个“快速过滤器”，用简单的计算（少参数、低精度）给每个词和前面所有词的“相关性”打分。比如读“苹果的价格是5元，香蕉的价格是3元”，看到“香蕉”时，索引器会快速判断“苹果”“价格”和它相关，打高分；其他无关词打低分。
   
2. **精细选Token机制**：只抓Top-k高分词  
   每个词只保留分数最高的k个词（比如2048个）进行深度计算，其他低分词直接忽略。比如上面的例子，“香蕉”只和“苹果”“价格”“5元”“3元”这些高分词互动，不用管其他无关内容。

#### 实际效果
- 处理128K长文本时，速度比旧版本快很多，在H800 GPU上的部署成本降低（比如每百万词处理成本从2.4美元降到0.7美元）；
- 长文本推理能力不下降，甚至在专门的长文本测试中分数更高。

### 技术2：可扩展强化学习（RL）框架—— 让模型“越练越强”
#### 问题背景
之前开源模型的后续训练（相当于“课后补习”）有两个问题：一是算力不够（补习时间太短），二是训练方法不稳定（越补越偏）。比如有的模型补了数学能力，却忘了怎么写代码。

#### 核心思路：“足量算力+稳定方法”双管齐下
1. **算力拉满**：后续训练的算力占预训练的10%以上（相当于预训练学完“基础知识”，后续训练花足够时间“专项刷题”）；
2. **方法优化**：在原有RL算法（GRPO）基础上，加了4个“稳定器”，避免模型学偏：

#### 4个“稳定器”
1. **无偏KL估计**：不让模型“钻牛角尖”  
   比如模型之前学过“1+1=2”，后续训练中如果有个错误样本说“1+1=3”，这个机制会纠正误差，不让模型为了迎合错误样本而跑偏。

2. **离线序列掩码**：过滤“坏数据”  
   训练数据中难免有“质量差、和模型当前能力偏差大”的样本（比如让小学生做微积分题），这个机制会把这些样本屏蔽掉，避免模型学坏。

3. **Keep Routing**：避免“训练和推理不一致”  
   有些模型训练时用了“专家分工”（比如A专家做数学，B专家写代码），但推理时却乱分配专家（让A专家写代码），导致效果变差。这个机制会强制训练和推理时“专家分工一致”。

4. **Keep Sampling Mask**：保证“训练和推理的规则一致”  
   推理时会过滤掉极低概率的词（比如生僻字、错误表达），训练时也会沿用这个规则，不让模型学这些没用的内容。

#### 强化版Speciale：放开“思考长度限制”
标准版为了效率，会限制模型的“思考字数”（比如最多想2000字就输出答案）；而Speciale版本专门针对推理任务，放开了这个限制，还加了数学证明专用数据，结果在2025年IMO（国际数学奥赛）、IOI（国际信息学奥赛）中拿到金牌，和Gemini-3.0-Pro持平。

### 技术3：大规模智能体任务合成 pipeline—— 让模型“会用工具”
#### 问题背景
开源模型不会“举一反三”用工具：比如训练时学了“用搜索查天气”，遇到“用搜索查景点门票”就不会了，核心是缺少“多样化的工具使用场景数据”。

#### 核心思路：人工合成“海量真实场景”，让模型多练
相当于给模型搭建了一个“工具使用训练场”，合成了1800多个不同环境、85000个复杂任务，让模型在里面反复练习，学会灵活用工具。

#### 3个关键步骤
1. **冷启动：先教模型“边想边用工具”**  
   给模型明确指令：“遇到问题先思考，思考时可以调用工具，比如用代码算数学题、用搜索查信息”，并给示例（比如“计算1+2+…+100”，让模型先想“用循环代码计算”，再调用代码工具执行）。

2. **合成多样化任务：覆盖4大场景**  
   针对不同工具场景，合成真实可验证的任务：
   - 搜索智能体：生成多语言、多领域的“搜索问答”（比如“查2025年杭州国庆天气”），还会验证答案是否正确；
   - 代码智能体：从GitHub挖“问题-解决方案”对（比如“修复Python代码的语法错误”），搭建可执行环境，让模型练代码调试；
   - 代码解释器：用Jupyter Notebook让模型练“用代码解决数学/数据问题”（比如“用代码画折线图”）；
   - 通用智能体：合成“旅行规划”这类复杂任务（比如“3天杭州出发旅行，不重复城市/酒店，按预算控制餐饮和景点”），提供15个工具（查景点、查交通、查酒店等），让模型练多工具协同。

3. **RL训练：让模型“越练越灵活”**  
   用合成的任务数据训练模型，还设计了“奖励机制”（比如用对工具加1分，用错减1分），让模型逐渐学会“什么时候用什么工具”。

## 三、性能表现：开源模型的“逆袭”
### 1. 核心能力对标闭源模型
| 能力类型 | 表现 |
|----------|------|
| 推理能力 | 标准版和GPT-5持平，在数学（AIME 2025）、逻辑推理（HLE）等测试中分数接近； |
| 代码能力 | Codeforces评分2386，超过大部分开源模型，接近GPT-5（2537）； |
| 工具使用 | 在搜索（BrowseComp）、代码调试（SWE-Verified）等测试中，大幅领先其他开源模型，缩小了和闭源模型的差距； |
| 竞赛成绩 | Speciale版本拿下IMO、IOI、CMO、ICPC世界总决赛金牌，成为首个在顶尖奥赛中拿金牌的开源模型。 |

### 2. 效率优势：又快又便宜
- 长文本处理：DSA让128K文本的推理速度比旧版本快30%+；
- 部署成本：在H800 GPU上，每百万词处理成本从2.4美元降到0.7美元（预填充场景），解码成本也大幅降低。

## 四、局限性与未来方向
### 目前的短板
1. 知识广度：预训练的总算力不如闭源模型，对一些冷门领域的知识了解不够；
2.  token效率：模型需要更长的“思考过程”（更多token）才能达到闭源模型的效果，比如Gemini-3.0-Pro想15000字能解决的问题，DeepSeek-V3.2可能需要27000字；
3. 复杂任务：面对超复杂的多步骤工具使用任务（比如“搭建一个完整的网站并部署”），还是不如Gemini-3.0-Pro。

### 未来要做的
1. 加预训练算力：扩大训练数据和算力，补齐知识广度；
2. 优化推理链：让模型“思考更精炼”，减少无用的思考步骤，提升token效率；
3. 改进基础模型：进一步优化架构和训练方法，提升复杂任务处理能力。

## 总结
DeepSeek-V3.2的核心价值是**给开源大模型提供了“效率+能力”的双突破方案**：用DSA解决“长文本慢”，用可扩展RL解决“训练不充分”，用大规模任务合成解决“工具不会用”。它不仅让开源模型能对标GPT-5，还通过Speciale版本证明了开源模型在顶尖竞赛中的潜力，为后续开源模型的发展提供了重要参考。如果需要实际使用，它的开源代码已经放在Hugging Face上，部署成本也比同类模型低，适合需要强推理、工具使用能力的场景（如代码开发、智能助手、学术研究）。